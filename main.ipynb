{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import nltk\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.238827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.426404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              spam\n",
       "count  5728.000000\n",
       "mean      0.238827\n",
       "std       0.426404\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5728 entries, 0 to 5727\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5728 non-null   object\n",
      " 1   spam    5728 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 89.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "display(data.head())\n",
    "display(data.describe())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4360\n",
      "1    1368\n",
      "Name: spam, dtype: int64\n",
      "0    0.761173\n",
      "1    0.238827\n",
      "Name: spam, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data['spam'].value_counts())\n",
    "print(data['spam'].value_counts(normalize=True))\n",
    "\n",
    "sns.countplot(data['spam'])\n",
    "plt.title('Category Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n",
      "0    345.804817\n",
      "1    266.432749\n",
      "Name: word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data['word_count'] = data['text'].str.split().str.len()\n",
    "\n",
    "print(data.groupby('spam')['word_count'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [subject, :, naturally, irresistible, your, co...\n",
      "1       [subject, :, the, stock, trading, gunslinger, ...\n",
      "2       [subject, :, unbelievable, new, homes, made, e...\n",
      "3       [subject, :, 4, color, printing, special, requ...\n",
      "4       [subject, :, do, not, have, money, ,, get, sof...\n",
      "                              ...                        \n",
      "5723    [subject, :, re, :, research, and, development...\n",
      "5724    [subject, :, re, :, receipts, from, visit, jim...\n",
      "5725    [subject, :, re, :, enron, case, study, update...\n",
      "5726    [subject, :, re, :, interest, david, ,, please...\n",
      "5727    [subject, :, news, :, aurora, 5, ., 2, update,...\n",
      "Name: text, Length: 5728, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tokenized_messages = data['text'].str.lower().apply(word_tokenize)\n",
    "print(tokenized_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [subject, naturally, irresistible, your, corpo...\n",
      "1       [subject, the, stock, trading, gunslinger, fan...\n",
      "2       [subject, unbelievable, new, homes, made, easy...\n",
      "3       [subject, color, printing, special, request, a...\n",
      "4       [subject, do, not, have, money, get, software,...\n",
      "                              ...                        \n",
      "5723    [subject, re, research, and, development, char...\n",
      "5724    [subject, re, receipts, from, visit, jim, than...\n",
      "5725    [subject, re, enron, case, study, update, wow,...\n",
      "5726    [subject, re, interest, david, please, call, s...\n",
      "5727    [subject, news, aurora, update, aurora, versio...\n",
      "Name: text, Length: 5728, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def alpha(tokens):\n",
    "    alpha = []\n",
    "    for token in tokens:\n",
    "        if str.isalpha(token) or token in ['n\\'t','won\\'t']:\n",
    "            if token == 'n\\'t':\n",
    "                alpha.append('not')\n",
    "                continue\n",
    "            elif token == 'won\\'t':\n",
    "                alpha.append('wont')\n",
    "                continue\n",
    "            alpha.append(token)\n",
    "    return alpha\n",
    "\n",
    "tokenized_messages = tokenized_messages.apply(alpha)\n",
    "print(tokenized_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [subject, naturally, irresistible, corporate, ...\n",
      "1       [subject, stock, trading, gunslinger, fanny, m...\n",
      "2       [subject, unbelievable, new, homes, made, easy...\n",
      "3       [subject, color, printing, special, request, a...\n",
      "4       [subject, money, get, software, cds, software,...\n",
      "                              ...                        \n",
      "5723    [subject, research, development, charges, gpg,...\n",
      "5724    [subject, receipts, visit, jim, thanks, invita...\n",
      "5725    [subject, enron, case, study, update, wow, day...\n",
      "5726    [subject, interest, david, please, call, shirl...\n",
      "5727    [subject, news, aurora, update, aurora, versio...\n",
      "Name: text, Length: 5728, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    no_stop = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords.words('english'):\n",
    "            no_stop.append(token)\n",
    "    return no_stop\n",
    "tokenized_messages = tokenized_messages.apply(remove_stop_words)\n",
    "print(tokenized_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       subject naturally irresistible corporate ident...\n",
      "1       subject stock trading gunslinger fanny merrill...\n",
      "2       subject unbelievable new home made easy im wan...\n",
      "3       subject color printing special request additio...\n",
      "4       subject money get software cd software compati...\n",
      "                              ...                        \n",
      "5723    subject research development charge gpg forwar...\n",
      "5724    subject receipt visit jim thanks invitation vi...\n",
      "5725    subject enron case study update wow day super ...\n",
      "5726    subject interest david please call shirley cre...\n",
      "5727    subject news aurora update aurora version fast...\n",
      "Name: text, Length: 5728, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    for token in tokens:\n",
    "        lemmatized.append(lemmatizer.lemmatize(token))\n",
    "    return \" \".join(lemmatized)\n",
    "\n",
    "tokenized_messages = tokenized_messages.apply(lemmatize)\n",
    "print(tokenized_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject naturally irresistible corporate ident...</td>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject unbelievable new home made easy im wan...</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject color printing special request additio...</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject money get software cd software compati...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subject great nnews hello welcome medzonline s...</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>subject hot play motion homeland security inve...</td>\n",
       "      <td>1</td>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subject save money buy getting thing tried cia...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subject undeliverable home based business grow...</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subject save money buy getting thing tried cia...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  word_count\n",
       "0  subject naturally irresistible corporate ident...     1         324\n",
       "1  subject stock trading gunslinger fanny merrill...     1          89\n",
       "2  subject unbelievable new home made easy im wan...     1          87\n",
       "3  subject color printing special request additio...     1          98\n",
       "4  subject money get software cd software compati...     1          52\n",
       "5  subject great nnews hello welcome medzonline s...     1          84\n",
       "6  subject hot play motion homeland security inve...     1        1703\n",
       "7  subject save money buy getting thing tried cia...     1          95\n",
       "8  subject undeliverable home based business grow...     1         121\n",
       "9  subject save money buy getting thing tried cia...     1          95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['text'] = tokenized_messages\n",
    "\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['text']\n",
    "y = data['spam']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state=34, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tf-idf vectorizer\n",
    "vectorizer = TfidfVectorizer(strip_accents='ascii')\n",
    "\n",
    "# First fit the vectorizer with our training set\n",
    "tfidf_train = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# Now we can fit our test data with the same vectorizer\n",
    "tfidf_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.981675392670157\n",
      "F1 score:  0.9613259668508287\n",
      "Accuracy:  0.9781849912739965\n",
      "F1 score:  0.9530956848030019\n",
      "Accuracy:  0.9790575916230366\n",
      "F1 score:  0.9550561797752808\n",
      "Accuracy:  0.9790575916230366\n",
      "F1 score:  0.9552238805970148\n",
      "Accuracy:  0.9781849912739965\n",
      "F1 score:  0.9536178107606679\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10,2):\n",
    "  model = KNeighborsClassifier(n_neighbors=i)\n",
    "  model.fit(tfidf_train,y_train)\n",
    "  predictedResult = model.predict(tfidf_test)\n",
    "  print(\"Accuracy: \",model.score(tfidf_test,y_test))\n",
    "  print(\"F1 score: \", metrics.f1_score(y_test,predictedResult))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_range = np.logspace(-2,10,13)\n",
    "gamma_range = np.logspace(-9,3,13)\n",
    "degree_range =  np.logspace(-2,10,13)\n",
    "kernel_range = np.array(['rbf','linear','poly'])\n",
    "params = {'kernel': kernel_range, 'c': c_range, 'gamma': gamma_range, 'degree':degree_range}\n",
    "param_grid = dict(gamma = gamma_range, C=c_range, degree=degree_range)\n",
    "cv = StratifiedShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 42)\n",
    "svm_cv = GridSearchCV(svm.SVC(),param_grid = param_grid,cv=cv)\n",
    "svm_cv.fit(tfidf_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_predict_test = svm_cv.predict(tfidf_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "print(svm_cv.best_estimator_)\n",
    "#sns.heatmap(cm, annot=True)\n",
    "#Evaluating Model\n",
    "print(classification_report(y_test, y_predict_test))\n",
    "print(\"test set\")\n",
    "print(\"\\nAccuracy Score: \" + str(metrics.accuracy_score(y_test, y_predict_test)))\n",
    "print(\"F1 Score: \" + str(metrics.f1_score(y_test, y_predict_test)))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y_test, y_predict_test)))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y_test, y_predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccb674ee3bab559fe921ecbe7478c68e22e296bea81f04b5c7d3451696244e75"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
